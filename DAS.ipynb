{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "from circuits_benchmark.utils import hf\n",
    "from circuits_benchmark.utils.get_cases import get_cases\n",
    "from circuits_benchmark.commands.build_main_parser import build_main_parser\n",
    "from circuits_benchmark.transformers.hooked_tracr_transformer import HookedTracrTransformer\n",
    "from argparse import Namespace\n",
    "\n",
    "parser_args = Namespace(task=3, model=\"510\")\n",
    "\n",
    "args, _ = build_main_parser().parse_known_args(\n",
    "    [\n",
    "        \"compile\",\n",
    "        f\"-i={parser_args.task}\",\n",
    "        \"-f\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "cases = get_cases(args)\n",
    "case = cases[0]\n",
    "if not case.supports_causal_masking():\n",
    "    raise NotImplementedError(f\"Case {case.get_index()} does not support causal masking\")\n",
    "\n",
    "tracr_output = case.build_tracr_model()\n",
    "hl_model = case.build_transformer_lens_model()\n",
    "\n",
    "cfg_dict = {\n",
    "        \"n_layers\": 2,\n",
    "        \"n_heads\": 4,\n",
    "        \"d_head\": 4,\n",
    "        \"d_model\": 8,\n",
    "        \"d_mlp\": 16,\n",
    "        \"seed\": 0,\n",
    "        \"act_fn\": \"gelu\",\n",
    "    }\n",
    "ll_cfg = hl_model.cfg.to_dict().copy()\n",
    "ll_cfg.update(cfg_dict)\n",
    "\n",
    "ll_model = HookedTracrTransformer(\n",
    "    ll_cfg, hl_model.tracr_input_encoder, hl_model.tracr_output_encoder, hl_model.residual_stream_labels,\n",
    "    remove_extra_tensor_cloning=True\n",
    ")\n",
    "ll_model.load_weights_from_file(f\"ll_models/{case.get_index()}/ll_model_{parser_args.model}.pth\")\n",
    "\n",
    "wrapped_ll_model = hf.make_hf_wrapper_from_tl_model(ll_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<circuits_benchmark.utils.iit.dataset.TracrIITDataset at 0x2b2e98d10>,\n",
       " <circuits_benchmark.utils.iit.dataset.TracrIITDataset at 0x2b1054210>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from circuits_benchmark.utils.iit import make_iit_hl_model, create_dataset\n",
    "iit_hl_model = make_iit_hl_model(hl_model)\n",
    "train_data, test_data = create_dataset(case, hl_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "loader = train_data.make_loader(batch_size, num_workers)\n",
    "test_loader = test_data.make_loader(batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvene import IntervenableModel, IntervenableConfig, RepresentationConfig, RotatedSpaceIntervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why twice of the same thing???\n",
    "\n",
    "config = IntervenableConfig(\n",
    "    model_type=type(wrapped_ll_model),\n",
    "    representations=[\n",
    "        RepresentationConfig(\n",
    "            0,  # layer\n",
    "            \"block_output\",  # intervention type\n",
    "            \"pos\",  # intervention unit is now aligne with tokens\n",
    "            1,  # max number of unit\n",
    "            subspace_partition=None,  # binary partition with equal sizes\n",
    "            intervention_link_key=0,\n",
    "        ),\n",
    "        RepresentationConfig(\n",
    "            0,  # layer\n",
    "            \"block_output\",  # intervention type\n",
    "            \"pos\",  # intervention unit is now aligne with tokens\n",
    "            1,  # max number of unit\n",
    "            subspace_partition=None,  # binary partition with equal sizes,\n",
    "            intervention_link_key=0,\n",
    "        ),\n",
    "    ],\n",
    "    intervention_types=RotatedSpaceIntervention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Detected use_fast=True means the intervention location will be static within a batch.\n",
      "\n",
      "In case multiple location tags are passed only the first one will be considered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_output\n",
      "n_embd\n",
      "model.blocks[0]\n",
      "block_output\n",
      "n_embd\n",
      "model.blocks[0]\n"
     ]
    }
   ],
   "source": [
    "intervenable = IntervenableModel(config, wrapped_ll_model, use_fast=True)\n",
    "intervenable.set_device(\"cpu\")\n",
    "intervenable.disable_model_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "gradient_accumulation_steps = 1\n",
    "# total_step = 0\n",
    "# target_total_step = len(train_data) * epochs\n",
    "\n",
    "optimizer_params = []\n",
    "for k, v in intervenable.interventions.items():\n",
    "    optimizer_params += [{\"params\": v[0].rotate_layer.parameters()}]\n",
    "    break\n",
    "optimizer = torch.optim.Adam(optimizer_params, lr=0.001)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds, eval_labels):\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for eval_pred, eval_label in zip(eval_preds, eval_labels):\n",
    "        total_count += 1\n",
    "        correct_count += eval_pred == eval_label\n",
    "    accuracy = float(correct_count) / float(total_count)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def compute_loss(outputs, labels):\n",
    "    CE = torch.nn.CrossEntropyLoss()\n",
    "    return CE(outputs, labels)\n",
    "\n",
    "\n",
    "def batched_random_sampler(data):\n",
    "    batch_indices = [_ for _ in range(int(len(data) / batch_size))]\n",
    "    random.shuffle(batch_indices)\n",
    "    for b_i in batch_indices:\n",
    "        for i in range(b_i * batch_size, (b_i + 1) * batch_size):\n",
    "            yield i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".iit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
