{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 2, 'd_model': 8, 'n_ctx': 5, 'd_head': 2, 'model_name': 'custom', 'n_heads': 4, 'd_mlp': 16, 'act_fn': 'gelu', 'd_vocab': 6, 'eps': 1e-05, 'use_attn_result': True, 'use_attn_scale': True, 'use_split_qkv_input': True, 'use_hook_mlp_in': True, 'use_attn_in': False, 'use_local_attn': False, 'original_architecture': None, 'from_checkpoint': False, 'checkpoint_index': None, 'checkpoint_label_type': None, 'checkpoint_value': None, 'tokenizer_name': None, 'window_size': None, 'attn_types': None, 'init_mode': 'gpt2', 'normalization_type': None, 'device': device(type='mps'), 'n_devices': 1, 'attention_dir': 'causal', 'attn_only': False, 'seed': 0, 'initializer_range': 0.22188007849009167, 'init_weights': True, 'scale_attn_by_inverse_layer_idx': False, 'positional_embedding_type': 'standard', 'final_rms': False, 'd_vocab_out': 1, 'parallel_attn_mlp': False, 'rotary_dim': None, 'n_params': 676, 'use_hook_tokens': False, 'gated_mlp': False, 'default_prepend_bos': True, 'dtype': torch.float32, 'tokenizer_prepends_bos': None, 'n_key_value_heads': None, 'post_embedding_ln': False, 'rotary_base': 10000, 'trust_remote_code': False, 'rotary_adjacent_pairs': False}\n"
     ]
    }
   ],
   "source": [
    "from circuits_benchmark.utils.get_cases import get_cases\n",
    "from circuits_benchmark.commands.build_main_parser import build_main_parser\n",
    "from iit_utils import create_dataset\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "task = 3\n",
    "args, _ = build_main_parser().parse_known_args(\n",
    "    [\n",
    "        \"compile\",\n",
    "        f\"-i={task}\",\n",
    "        \"-f\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "cases = get_cases(args)\n",
    "case = cases[0]\n",
    "\n",
    "hl_model = case.build_transformer_lens_model()\n",
    "\n",
    "train_data, test_data = create_dataset(case, hl_model)\n",
    "\n",
    "cfg_dict = {\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_head\": 2,\n",
    "    \"d_model\": 8,\n",
    "    \"d_mlp\": 16,\n",
    "    \"seed\": 0,\n",
    "    \"act_fn\": \"gelu\",\n",
    "}\n",
    "ll_cfg = hl_model.cfg.to_dict().copy()\n",
    "ll_cfg.update(cfg_dict)\n",
    "print(ll_cfg)\n",
    "model = HookedTransformer(ll_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, PreTrainedModel, PretrainedConfig, GPT2Config, GPT2Model\n",
    "from pyvene import IntervenableModel, IntervenableConfig\n",
    "\n",
    "my_config = GPT2Config(\n",
    "        vocab_size=ll_cfg['d_vocab'],\n",
    "        n_positions=ll_cfg['n_ctx'],\n",
    "        n_embd=ll_cfg['d_model'],\n",
    "        n_layer=ll_cfg['n_layers'],\n",
    "        n_head=ll_cfg['n_heads'],\n",
    "        n_inner=ll_cfg['d_mlp'], # TODO: check if this is correct\n",
    "        activation_function=ll_cfg['act_fn'],\n",
    "        resid_pdrop=0,\n",
    "        embd_pdrop=0,\n",
    "        attn_pdrop=0,\n",
    "        layer_norm_epsilon=ll_cfg['eps'],\n",
    "\n",
    "        # not sure if we need to change these...\n",
    "        initializer_range=0.02,\n",
    "        summary_type=\"cls_index\",\n",
    "        summary_use_proj=True,\n",
    "        summary_activation=None,\n",
    "        summary_proj_to_labels=True,\n",
    "        summary_first_dropout=0.0,\n",
    "        scale_attn_weights=True,\n",
    "        use_cache=True,\n",
    "        bos_token_id=50256,\n",
    "        eos_token_id=50256,\n",
    "        scale_attn_by_inverse_layer_idx=False,\n",
    "        reorder_and_upcast_attn=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IntervenableTLConfig(IntervenableConfig):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "# class IntervenableTLModel(IntervenableModel):\n",
    "#     def __init__(self, config, model, **kwargs):\n",
    "#         super().__init__(config, model, **kwargs)\n",
    "import transformers.models as hf_models\n",
    "class TLModel(PreTrainedModel):\n",
    "    def __init__(self, tl_config: HookedTransformerConfig, *inputs, config= my_config, **kwargs):\n",
    "        super().__init__(config, *inputs, **kwargs)\n",
    "        self.model = HookedTransformer(tl_config)\n",
    "        self.tl_config = tl_config\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "    \n",
    "\n",
    "\n",
    "# AutoModel.register(GPT2Config, TLModel)\n",
    "transformers_model = TLModel(ll_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvene.models.constants import *\n",
    "tl_to_module_mapping = {\n",
    "    \"block_input\": (\"model.blocks[%s]\", CONST_INPUT_HOOK),\n",
    "    \"block_output\": (\"model.blocks[%s]\", CONST_OUTPUT_HOOK),\n",
    "    # \"mlp_activation\": (\"model.blocks[%s].mlp.act\", CONST_OUTPUT_HOOK),\n",
    "    \"mlp_output\": (\"model.blocks[%s].mlp\", CONST_OUTPUT_HOOK),\n",
    "    \"mlp_input\": (\"model.blocks[%s].mlp\", CONST_INPUT_HOOK),\n",
    "\n",
    "    # \"attention_value_output\": (\"model.blocks[%s].attn.hook_v\", CONST_INPUT_HOOK),\n",
    "    # \"head_attention_value_output\": (\"model.blocks[%s].attn.hook_\", CONST_INPUT_HOOK, (split_head_and_permute, \"n_head\")),\n",
    "    # \"attention_weight\": (\"model.blocks[%s].attn.attn_dropout\", CONST_INPUT_HOOK),\n",
    "    \"attention_output\": (\"model.blocks[%s].attn.hook_result\", CONST_OUTPUT_HOOK),\n",
    "    \"attention_input\": (\"model.blocks[%s].hook_attn_in\", CONST_INPUT_HOOK),\n",
    "\n",
    "    # \"query_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 0)),\n",
    "    # \"key_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 1)),\n",
    "    # \"value_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 2)),\n",
    "    # \"head_query_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 0), (split_head_and_permute, \"n_head\")), \n",
    "    # \"head_key_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 1), (split_head_and_permute, \"n_head\")),\n",
    "    # \"head_value_output\": (\"model.blocks[%s].attn.c_attn\", CONST_OUTPUT_HOOK, (split_three, 2), (split_head_and_permute, \"n_head\")),\n",
    "}\n",
    "\n",
    "tl_to_dimension_mapping = {\n",
    "    \"n_head\": (\"n_head\", ),\n",
    "    \"block_input\": (\"n_embd\",),\n",
    "    \"block_output\": (\"n_embd\",),\n",
    "    \"mlp_activation\": (\n",
    "        \"n_inner\",\n",
    "        \"n_embd*4\",\n",
    "    ),\n",
    "    \"mlp_output\": (\"n_embd\",),\n",
    "    \"mlp_input\": (\"n_embd\",),\n",
    "    \"attention_value_output\": (\"n_embd\",),\n",
    "    \"head_attention_value_output\": (\"n_embd/n_head\",),\n",
    "    \"attention_weight\": (\"max_position_embeddings\", ),\n",
    "    \"attention_output\": (\"n_embd\",),\n",
    "    \"attention_input\": (\"n_embd\",),\n",
    "    \"query_output\": (\"n_embd\",),\n",
    "    \"key_output\": (\"n_embd\",),\n",
    "    \"value_output\": (\"n_embd\",),\n",
    "    \"head_query_output\": (\"n_embd/n_head\",),\n",
    "    \"head_key_output\": (\"n_embd/n_head\",),\n",
    "    \"head_value_output\": (\"n_embd/n_head\",),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvene.models.intervenable_modelcard import type_to_module_mapping, type_to_dimension_mapping\n",
    "\n",
    "type_to_module_mapping[type(transformers_model)] = tl_to_module_mapping\n",
    "type_to_dimension_mapping[type(transformers_model)] = tl_to_dimension_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PretrainedConfig().get_config_dict('hooked_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    RotatedSpaceIntervention,\n",
    "    RepresentationConfig,\n",
    "    IntervenableConfig,\n",
    ")\n",
    "subspace_partition=[[0, model.cfg.n_layers//2], [model.cfg.n_layers//2, model.cfg.n_layers]]\n",
    "intervenable_config = IntervenableConfig(\n",
    "        # model_type=type(transformers_model),\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                1,  # layer\n",
    "                \"attention_output\",  # repr intervention type\n",
    "                \"pos\",  # intervention unit\n",
    "                1,      # max number of unit\n",
    "                subspace_partition=subspace_partition,\n",
    "            )\n",
    "        ],\n",
    "        intervention_types=RotatedSpaceIntervention,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output\n",
      "n_embd\n",
      "model.blocks[1].attn.hook_result\n"
     ]
    }
   ],
   "source": [
    "intervenable_model = IntervenableModel(intervenable_config, transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('layer.1.comp.attention_output.unit.pos.nunit.1#0', (RotatedSpaceIntervention(\n",
       "  (rotate_layer): ParametrizedRotateLayer(\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): _Orthogonal()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), <bound method Module.register_forward_hook of HookPoint()>))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervenable_model.interventions.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
      "<class 'torch.nn.modules.sparse.Embedding'>\n",
      "<class 'torch.nn.modules.sparse.Embedding'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.container.ModuleList'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.activations.GELUActivation'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.pytorch_utils.Conv1D'>\n",
      "<class 'transformers.activations.GELUActivation'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n"
     ]
    }
   ],
   "source": [
    "g2m = GPT2Model(my_config)\n",
    "for module in g2m.modules():\n",
    "    print(module.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.models.gpt2.modeling_gpt2 import GPT2Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-1): 2 x TransformerBlock(\n",
      "      (ln1): Identity()\n",
      "      (ln2): Identity()\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n",
      "Embed()\n",
      "PosEmbed()\n",
      "ModuleList(\n",
      "  (0-1): 2 x TransformerBlock(\n",
      "    (ln1): Identity()\n",
      "    (ln2): Identity()\n",
      "    (attn): Attention(\n",
      "      (hook_k): HookPoint()\n",
      "      (hook_q): HookPoint()\n",
      "      (hook_v): HookPoint()\n",
      "      (hook_z): HookPoint()\n",
      "      (hook_attn_scores): HookPoint()\n",
      "      (hook_pattern): HookPoint()\n",
      "      (hook_result): HookPoint()\n",
      "    )\n",
      "    (mlp): MLP(\n",
      "      (hook_pre): HookPoint()\n",
      "      (hook_post): HookPoint()\n",
      "    )\n",
      "    (hook_attn_in): HookPoint()\n",
      "    (hook_q_input): HookPoint()\n",
      "    (hook_k_input): HookPoint()\n",
      "    (hook_v_input): HookPoint()\n",
      "    (hook_mlp_in): HookPoint()\n",
      "    (hook_attn_out): HookPoint()\n",
      "    (hook_mlp_out): HookPoint()\n",
      "    (hook_resid_pre): HookPoint()\n",
      "    (hook_resid_mid): HookPoint()\n",
      "    (hook_resid_post): HookPoint()\n",
      "  )\n",
      ")\n",
      "TransformerBlock(\n",
      "  (ln1): Identity()\n",
      "  (ln2): Identity()\n",
      "  (attn): Attention(\n",
      "    (hook_k): HookPoint()\n",
      "    (hook_q): HookPoint()\n",
      "    (hook_v): HookPoint()\n",
      "    (hook_z): HookPoint()\n",
      "    (hook_attn_scores): HookPoint()\n",
      "    (hook_pattern): HookPoint()\n",
      "    (hook_result): HookPoint()\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (hook_pre): HookPoint()\n",
      "    (hook_post): HookPoint()\n",
      "  )\n",
      "  (hook_attn_in): HookPoint()\n",
      "  (hook_q_input): HookPoint()\n",
      "  (hook_k_input): HookPoint()\n",
      "  (hook_v_input): HookPoint()\n",
      "  (hook_mlp_in): HookPoint()\n",
      "  (hook_attn_out): HookPoint()\n",
      "  (hook_mlp_out): HookPoint()\n",
      "  (hook_resid_pre): HookPoint()\n",
      "  (hook_resid_mid): HookPoint()\n",
      "  (hook_resid_post): HookPoint()\n",
      ")\n",
      "Identity()\n",
      "Identity()\n",
      "Attention(\n",
      "  (hook_k): HookPoint()\n",
      "  (hook_q): HookPoint()\n",
      "  (hook_v): HookPoint()\n",
      "  (hook_z): HookPoint()\n",
      "  (hook_attn_scores): HookPoint()\n",
      "  (hook_pattern): HookPoint()\n",
      "  (hook_result): HookPoint()\n",
      ")\n",
      "MLP(\n",
      "  (hook_pre): HookPoint()\n",
      "  (hook_post): HookPoint()\n",
      ")\n",
      "TransformerBlock(\n",
      "  (ln1): Identity()\n",
      "  (ln2): Identity()\n",
      "  (attn): Attention(\n",
      "    (hook_k): HookPoint()\n",
      "    (hook_q): HookPoint()\n",
      "    (hook_v): HookPoint()\n",
      "    (hook_z): HookPoint()\n",
      "    (hook_attn_scores): HookPoint()\n",
      "    (hook_pattern): HookPoint()\n",
      "    (hook_result): HookPoint()\n",
      "  )\n",
      "  (mlp): MLP(\n",
      "    (hook_pre): HookPoint()\n",
      "    (hook_post): HookPoint()\n",
      "  )\n",
      "  (hook_attn_in): HookPoint()\n",
      "  (hook_q_input): HookPoint()\n",
      "  (hook_k_input): HookPoint()\n",
      "  (hook_v_input): HookPoint()\n",
      "  (hook_mlp_in): HookPoint()\n",
      "  (hook_attn_out): HookPoint()\n",
      "  (hook_mlp_out): HookPoint()\n",
      "  (hook_resid_pre): HookPoint()\n",
      "  (hook_resid_mid): HookPoint()\n",
      "  (hook_resid_post): HookPoint()\n",
      ")\n",
      "Identity()\n",
      "Identity()\n",
      "Attention(\n",
      "  (hook_k): HookPoint()\n",
      "  (hook_q): HookPoint()\n",
      "  (hook_v): HookPoint()\n",
      "  (hook_z): HookPoint()\n",
      "  (hook_attn_scores): HookPoint()\n",
      "  (hook_pattern): HookPoint()\n",
      "  (hook_result): HookPoint()\n",
      ")\n",
      "MLP(\n",
      "  (hook_pre): HookPoint()\n",
      "  (hook_post): HookPoint()\n",
      ")\n",
      "Unembed()\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens.components import Attention\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "for module in model.modules():\n",
    "    if isinstance(module, HookPoint):\n",
    "        continue\n",
    "    # if isinstance(module, Attention):\n",
    "        # print(module)\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# tokens = tokenizer(\"Hello, \", return_tensors=\"pt\")[\"input_ids\"]\n",
    "# tokens = torch.tensor(tokens).unsqueeze(0)\n",
    "cfg_dict = {\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_head\": 2,\n",
    "    \"d_model\": 8,\n",
    "    \"d_mlp\": 16,\n",
    "    \"seed\": 0,\n",
    "    \"act_fn\": \"gelu\",\n",
    "    \"n_ctx\": 10,\n",
    "    \"d_vocab\": 10,\n",
    "}\n",
    "model = HookedTransformer(cfg_dict)\n",
    "output, cache = model.run_with_cache(torch.tensor([[1, 2, 3,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, torch.Size([1, 3, 10]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.d_vocab, model.cfg.n_ctx, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4, 2]), 4, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"blocks.0.attn.hook_q\"].shape, model.cfg.n_heads, model.cfg.d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".iit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
